{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Full Stack Machine Learning's Week 4 Project!\n",
    "\n",
    "In the final week, you will return to the workflow you built last week on the [taxi dataset](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Deploy the champion\n",
    "Use what you have learned in the last two weeks to make necessary modifications and to deploy your latest version of the `TaxiFarePrediction` flow to Argo. Use `--branch champion` to denote this deployment as the champion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-10 08:32:10</td>\n",
       "      <td>2023-05-10 08:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>9.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-10 08:55:08</td>\n",
       "      <td>2023-05-10 09:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-10 08:25:04</td>\n",
       "      <td>2023-05-10 08:37:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>14.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-10 08:03:48</td>\n",
       "      <td>2023-05-10 08:13:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12.10</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-10 08:10:29</td>\n",
       "      <td>2023-05-10 08:21:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>11.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018702</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-21 14:16:41</td>\n",
       "      <td>2023-05-21 14:46:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>170</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>17.51</td>\n",
       "      <td>6.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018703</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-21 14:12:26</td>\n",
       "      <td>2023-05-21 14:28:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>151</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>25.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018704</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-21 14:45:09</td>\n",
       "      <td>2023-05-21 14:57:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>16.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018706</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-21 14:36:20</td>\n",
       "      <td>2023-05-21 14:46:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>224</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>14.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018708</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-21 14:12:00</td>\n",
       "      <td>2023-05-21 14:25:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>232</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>18.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1014479 rows √ó 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               2  2023-05-10 08:32:10   2023-05-10 08:40:36              1.0   \n",
       "1               2  2023-05-10 08:55:08   2023-05-10 09:01:27              1.0   \n",
       "2               2  2023-05-10 08:25:04   2023-05-10 08:37:49              1.0   \n",
       "3               1  2023-05-10 08:03:48   2023-05-10 08:13:25              0.0   \n",
       "4               2  2023-05-10 08:10:29   2023-05-10 08:21:19              1.0   \n",
       "...           ...                  ...                   ...              ...   \n",
       "3018702         2  2023-05-21 14:16:41   2023-05-21 14:46:34              NaN   \n",
       "3018703         2  2023-05-21 14:12:26   2023-05-21 14:28:10              NaN   \n",
       "3018704         2  2023-05-21 14:45:09   2023-05-21 14:57:15              NaN   \n",
       "3018706         2  2023-05-21 14:36:20   2023-05-21 14:46:32              NaN   \n",
       "3018708         2  2023-05-21 14:12:00   2023-05-21 14:25:00              NaN   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 0.97         1.0                  N           161   \n",
       "1                 1.10         1.0                  N            43   \n",
       "2                 2.51         1.0                  N            48   \n",
       "3                 1.90         1.0                  N           138   \n",
       "4                 1.43         1.0                  N           107   \n",
       "...                ...         ...                ...           ...   \n",
       "3018702          16.30         NaN               None           170   \n",
       "3018703           5.58         NaN               None           151   \n",
       "3018704           2.40         NaN               None            75   \n",
       "3018706           2.00         NaN               None           224   \n",
       "3018708           3.45         NaN               None           232   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                 141             2         9.30   1.00      0.5        0.00   \n",
       "1                 237             1         7.90   1.00      0.5        4.00   \n",
       "2                 238             1        14.90   1.00      0.5       15.00   \n",
       "3                   7             1        12.10   7.25      0.5        0.00   \n",
       "4                  79             1        11.40   1.00      0.5        3.28   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "3018702           132             0        77.00   0.00      0.5       17.51   \n",
       "3018703           137             0        25.36   0.00      0.5        2.00   \n",
       "3018704           140             0        16.04   0.00      0.5        3.01   \n",
       "3018706           162             0        14.28   0.00      0.5        0.00   \n",
       "3018708           164             0        18.88   0.00      0.5        4.58   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0                0.00                    1.0         14.30   \n",
       "1                0.00                    1.0         16.90   \n",
       "2                0.00                    1.0         34.90   \n",
       "3                0.00                    1.0         20.85   \n",
       "4                0.00                    1.0         19.68   \n",
       "...               ...                    ...           ...   \n",
       "3018702          6.55                    1.0        105.06   \n",
       "3018703          0.00                    1.0         31.36   \n",
       "3018704          0.00                    1.0         23.05   \n",
       "3018706          0.00                    1.0         18.28   \n",
       "3018708          0.00                    1.0         27.46   \n",
       "\n",
       "         congestion_surcharge  airport_fee  hour  \n",
       "0                         2.5         0.00     0  \n",
       "1                         2.5         0.00     1  \n",
       "2                         2.5         0.00     0  \n",
       "3                         0.0         1.25     0  \n",
       "4                         2.5         0.00     0  \n",
       "...                       ...          ...   ...  \n",
       "3018702                   NaN          NaN   270  \n",
       "3018703                   NaN          NaN   270  \n",
       "3018704                   NaN          NaN   270  \n",
       "3018706                   NaN          NaN   270  \n",
       "3018708                   NaN          NaN   270  \n",
       "\n",
       "[1014479 rows x 20 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_champ1 = pd.read_parquet('https://outerbounds-datasets.s3.us-west-2.amazonaws.com/taxi/latest.parquet')\n",
    "df_champ1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Build the challenger\n",
    "Develop a second model, by using the same `TaxiFarePrediction` architecture. Then, deploy the flow to Argo as the `--branch challenger`. \n",
    "<br>\n",
    "<br>\n",
    "Hint: Modify the `linear_model` step. \n",
    "<br>\n",
    "Bonus: Write a paragraph summary of how you developed the second model and tested it before deploying the challenger flow. Let us know in Slack what you found challenging about the task? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../flows/cloud/foo_taxi_fare_champion_1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../flows/cloud/foo_taxi_fare_champion_1.py\n",
    "\n",
    "from metaflow import FlowSpec, step, card, conda_base, current, Parameter, Flow, trigger, project\n",
    "from metaflow.cards import Markdown, Table, Image, Artifact\n",
    "\n",
    "\n",
    "URL = 'https://outerbounds-datasets.s3.us-west-2.amazonaws.com/taxi/latest.parquet'\n",
    "DATETIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "@project(name=\"foo_taxi_fare\")\n",
    "@trigger(events=['s3'])\n",
    "@conda_base(libraries={'pandas': '1.4.2', 'pyarrow': '11.0.0', 'numpy': '1.21.2', 'scikit-learn': '1.1.2'})\n",
    "class TaxiFarePrediction_Foo(FlowSpec):\n",
    "\n",
    "    data_url = Parameter(\"data_url\", default='https://outerbounds-datasets.s3.us-west-2.amazonaws.com/taxi/latest.parquet')\n",
    "\n",
    "    def transform_features(self, df):\n",
    "\n",
    "        # TODO: \n",
    "            # Try to complete tasks 2 and 3 with this function doing nothing like it currently is.\n",
    "            # Understand what is happening.\n",
    "            # Revisit task 1 and think about what might go in this function.\n",
    "        obviously_bad_data_filters = [\n",
    "\n",
    "            df.fare_amount > 0,         # fare_amount in US Dollars\n",
    "            df.trip_distance <= 100,    # trip_distance in miles\n",
    "            df.trip_distance > 0,\n",
    "            df.passenger_count > 0,\n",
    "            df.extra > 0,\n",
    "            df.mta_tax > 0,\n",
    "            df.tip_amount >= 0,\n",
    "            df.tolls_amount >= 0,\n",
    "\n",
    "            # TODO: add some logic to filter out what you decide is bad data!\n",
    "            # TIP: Don't spend too much time on this step for this project though, it practice it is a never-ending process.\n",
    "\n",
    "        ]\n",
    "\n",
    "        for f in obviously_bad_data_filters:\n",
    "            df = df[f]\n",
    "        return df\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "\n",
    "        import pandas as pd\n",
    "        import io\n",
    "        import requests\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        self.df = self.transform_features(pd.read_parquet('https://outerbounds-datasets.s3.us-west-2.amazonaws.com/taxi/latest.parquet'))\n",
    "\n",
    "        # NOTE: we are split into training and validation set in the validation step which uses cross_val_score.\n",
    "        # This is a simple/naive way to do this, and is meant to keep this example simple, to focus learning on deploying Metaflow flows.\n",
    "        # In practice, you want split time series data in more sophisticated ways and run backtests. \n",
    "        self.X = self.df[\"trip_distance\"].values.reshape(-1, 1)\n",
    "        self.y = self.df[\"total_amount\"].values\n",
    "        self.next(self.linear_model)\n",
    "\n",
    "    @step\n",
    "    def linear_model(self):\n",
    "        \"Fit a single variable, linear model to the data.\"\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "\n",
    "        # TODO: Play around with the model if you are feeling it.\n",
    "        self.model = LinearRegression()\n",
    "        self.model_type = \"linear regressor\"\n",
    "        self.next(self.validate)\n",
    "\n",
    "    def gather_sibling_flow_run_results(self):\n",
    "\n",
    "        # storage to populate and feed to a Table in a Metaflow card\n",
    "        rows = []\n",
    "\n",
    "        # loop through runs of this flow \n",
    "        for run in Flow(self.__class__.__name__):\n",
    "            if run.id != current.run_id:\n",
    "                if run.successful:\n",
    "                    icon = \"‚úÖ\" \n",
    "                    msg = \"OK\"\n",
    "                    score = str(run.data.scores.mean())\n",
    "                else:\n",
    "                    icon = \"‚ùå\"\n",
    "                    msg = \"Error\"\n",
    "                    score = \"NA\"\n",
    "                    for step in run:\n",
    "                        for task in step:\n",
    "                            if not task.successful:\n",
    "                                msg = task.stderr\n",
    "                row = [Markdown(icon), Artifact(run.id), Artifact(run.created_at.strftime(DATETIME_FORMAT)), Artifact(score), Markdown(msg)]\n",
    "                rows.append(row)\n",
    "            else:\n",
    "                rows.append([Markdown(\"‚úÖ\"), Artifact(run.id), Artifact(run.created_at.strftime(DATETIME_FORMAT)), Artifact(str(self.scores.mean())), Markdown(\"This run...\")])\n",
    "        return rows\n",
    "                \n",
    "    \n",
    "    @card(type=\"corise\")\n",
    "    @step\n",
    "    def validate(self):\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        self.scores = cross_val_score(self.model, self.X, self.y, cv=5)\n",
    "        current.card.append(Markdown(\"# Taxi Fare Prediction Results\"))\n",
    "        current.card.append(Table(self.gather_sibling_flow_run_results(), headers=[\"Pass/fail\", \"Run ID\", \"Created At\", \"R^2 score\", \"Stderr\"]))\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        print(\"Success!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TaxiFarePrediction_Foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Metaflow\n",
      "  Downloading metaflow-2.9.1-py2.py3-none-any.whl (926 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.8/site-packages (from Metaflow) (2.29.0)\n",
      "Requirement already satisfied: boto3 in /home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.8/site-packages (from Metaflow) (1.26.121)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.121 in /home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.8/site-packages (from boto3->Metaflow) (1.29.121)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.8/site-packages (from boto3->Metaflow) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.8/site-packages (from boto3->Metaflow) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.8/site-packages (from requests->Metaflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.8/site-packages (from requests->Metaflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.8/site-packages (from requests->Metaflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.8/site-packages (from requests->Metaflow) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.8/site-packages (from botocore<1.30.0,>=1.29.121->boto3->Metaflow) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.121->boto3->Metaflow) (1.16.0)\n",
      "Installing collected packages: Metaflow\n",
      "Successfully installed Metaflow-2.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install Metaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.9.1+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction_Foo\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mProject: \u001b[0m\u001b[32m\u001b[1mfoo_taxi_fare\u001b[0m\u001b[35m\u001b[22m, Branch: \u001b[0m\u001b[32m\u001b[1mprod.champion\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m2023-05-21 14:51:49.321 \u001b[0m\u001b[22mCreating local datastore in current directory (/home/workspace/workspaces/full-stack-ml-metaflow-corise-week-4/project/.metaflow)\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[1mDeploying \u001b[0m\u001b[31m\u001b[1mfootaxifare.prod.champion.taxifarepredictionfoo\u001b[0m\u001b[1m to Argo Workflows...\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22mIt seems this is the first time you are deploying \u001b[0m\u001b[31m\u001b[1mfootaxifare.prod.champion.taxifarepredictionfoo\u001b[0m\u001b[22m to Argo Workflows.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mA new production token generated.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mThe namespace of this production flow is\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    production:mfprj-sh5wdhgelehxd3cq-0-hrge\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mTo analyze results of this production flow add this line in your notebooks:\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    namespace(\"production:mfprj-sh5wdhgelehxd3cq-0-hrge\")\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mIf you want to authorize other people to deploy new versions of this flow to Argo Workflows, they need to call\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    argo-workflows create --authorize mfprj-sh5wdhgelehxd3cq-0-hrge\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mwhen deploying this flow to Argo Workflows for the first time.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mSee \"Organizing Results\" at https://docs.metaflow.org/ for more information about production tokens.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mBootstrapping conda environment...(this could take a few minutes)\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[1mWorkflow \u001b[0m\u001b[31m\u001b[1mfootaxifare.prod.champion.taxifarepredictionfoo\u001b[0m\u001b[1m for flow \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction_Foo\u001b[0m\u001b[1m pushed to Argo Workflows successfully.\n",
      "\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22mNote that the flow was deployed with a modified name due to Kubernetes naming conventions\n",
      "on Argo Workflows. The original flow name is stored in the workflow annotation.\n",
      "\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[1mSee the deployed workflow here:\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22m    https://argo-pw-1679610794.outerbounds.dev/workflow-templates/jobs-pw-1679610794/footaxifare.prod.champion.taxifarepredictionfoo\n",
      "    \u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[1mWhat will trigger execution of the workflow:\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22m    This workflow triggers automatically when the upstream \u001b[0m\u001b[31m\u001b[1ms3\u001b[0m\u001b[22m event is/are published.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python ../flows/cloud/foo_taxi_fare_champion_1.py --environment=conda --production --branch champion argo-workflows create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../flows/cloud/foo_taxi_fare_challenger_1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../flows/cloud/foo_taxi_fare_challenger_1.py\n",
    "\n",
    "# Let's use a modified version of the event_triggered_linear_regression.py file from week 3 as the champion.\n",
    "# Note that I encountered problems with reading the parquet url, and potentially saw some issues with caching - I had to explicitly state the parquet url and make sure\n",
    "# to write the contents of the cell to a new file, using a different flow class name to make it work. Did not get to the root cause of the problem due to time limitations.\n",
    "\n",
    "from metaflow import FlowSpec, step, card, conda_base, current, Parameter, Flow, trigger, project\n",
    "from metaflow.cards import Markdown, Table, Image, Artifact\n",
    "\n",
    "\n",
    "URL = 'https://outerbounds-datasets.s3.us-west-2.amazonaws.com/taxi/latest.parquet'\n",
    "DATETIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "@project(name=\"foo_taxi_fare\")\n",
    "@trigger(events=['s3'])\n",
    "\n",
    "@conda_base(libraries={'pandas': '1.4.2', 'pyarrow': '11.0.0', 'numpy': '1.21.2', 'scikit-learn': '1.1.2', 'xgboost': '1.7.4'})\n",
    "class TaxiFarePrediction_Foo(FlowSpec):\n",
    "\n",
    "    data_url = Parameter(\"data_url\", default='https://outerbounds-datasets.s3.us-west-2.amazonaws.com/taxi/latest.parquet')\n",
    "\n",
    "    def transform_features(self, df):\n",
    "\n",
    "        # TODO: \n",
    "            # Try to complete tasks 2 and 3 with this function doing nothing like it currently is.\n",
    "            # Understand what is happening.\n",
    "            # Revisit task 1 and think about what might go in this function.\n",
    "        obviously_bad_data_filters = [\n",
    "\n",
    "            df.fare_amount > 0,         # fare_amount in US Dollars\n",
    "            df.trip_distance <= 100,    # trip_distance in miles\n",
    "            df.trip_distance > 0,\n",
    "            df.passenger_count > 0,\n",
    "            df.extra > 0,\n",
    "            df.mta_tax > 0,\n",
    "            df.tip_amount >= 0,\n",
    "            df.tolls_amount >= 0,\n",
    "\n",
    "            # TODO: add some logic to filter out what you decide is bad data!\n",
    "            # TIP: Don't spend too much time on this step for this project though, it practice it is a never-ending process.\n",
    "\n",
    "        ]\n",
    "\n",
    "        for f in obviously_bad_data_filters:\n",
    "            df = df[f]\n",
    "        return df\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "\n",
    "        import pandas as pd\n",
    "        import io\n",
    "        import requests\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        self.df = self.transform_features(pd.read_parquet('https://outerbounds-datasets.s3.us-west-2.amazonaws.com/taxi/latest.parquet'))\n",
    "\n",
    "        # NOTE: we are split into training and validation set in the validation step which uses cross_val_score.\n",
    "        # This is a simple/naive way to do this, and is meant to keep this example simple, to focus learning on deploying Metaflow flows.\n",
    "        # In practice, you want split time series data in more sophisticated ways and run backtests. \n",
    "        self.X = self.df[\"trip_distance\"].values.reshape(-1, 1)\n",
    "        self.y = self.df[\"total_amount\"].values\n",
    "        self.next(self.xgboost_model)\n",
    "\n",
    "    @step\n",
    "    def xgboost_model(self):\n",
    "        from xgboost import XGBRegressor\n",
    "        self.model = XGBRegressor()\n",
    "        self.model_type = \"xgboos\"\n",
    "        self.next(self.validate)\n",
    "\n",
    "    def gather_sibling_flow_run_results(self):\n",
    "\n",
    "        # storage to populate and feed to a Table in a Metaflow card\n",
    "        rows = []\n",
    "\n",
    "        # loop through runs of this flow \n",
    "        for run in Flow(self.__class__.__name__):\n",
    "            if run.id != current.run_id:\n",
    "                if run.successful:\n",
    "                    icon = \"‚úÖ\" \n",
    "                    msg = \"OK\"\n",
    "                    score = str(run.data.scores.mean())\n",
    "                else:\n",
    "                    icon = \"‚ùå\"\n",
    "                    msg = \"Error\"\n",
    "                    score = \"NA\"\n",
    "                    for step in run:\n",
    "                        for task in step:\n",
    "                            if not task.successful:\n",
    "                                msg = task.stderr\n",
    "                row = [Markdown(icon), Artifact(run.id), Artifact(run.created_at.strftime(DATETIME_FORMAT)), Artifact(score), Markdown(msg)]\n",
    "                rows.append(row)\n",
    "            else:\n",
    "                rows.append([Markdown(\"‚úÖ\"), Artifact(run.id), Artifact(run.created_at.strftime(DATETIME_FORMAT)), Artifact(str(self.scores.mean())), Markdown(\"This run...\")])\n",
    "        return rows\n",
    "                \n",
    "    \n",
    "    @card(type=\"corise\")\n",
    "    @step\n",
    "    def validate(self):\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        self.scores = cross_val_score(self.model, self.X, self.y, cv=5)\n",
    "        current.card.append(Markdown(\"# Taxi Fare Prediction Results\"))\n",
    "        current.card.append(Table(self.gather_sibling_flow_run_results(), headers=[\"Pass/fail\", \"Run ID\", \"Created At\", \"R^2 score\", \"Stderr\"]))\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        print(\"Success!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TaxiFarePrediction_Foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.9.1+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction_Foo\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mProject: \u001b[0m\u001b[32m\u001b[1mfoo_taxi_fare\u001b[0m\u001b[35m\u001b[22m, Branch: \u001b[0m\u001b[32m\u001b[1mprod.challenger\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[1mDeploying \u001b[0m\u001b[31m\u001b[1mfootaxifare.prod.challenger.taxifarepredictionfoo\u001b[0m\u001b[1m to Argo Workflows...\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22mIt seems this is the first time you are deploying \u001b[0m\u001b[31m\u001b[1mfootaxifare.prod.challenger.taxifarepredictionfoo\u001b[0m\u001b[22m to Argo Workflows.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mA new production token generated.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mThe namespace of this production flow is\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    production:mfprj-y22g5oex2j23upte-0-sezo\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mTo analyze results of this production flow add this line in your notebooks:\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    namespace(\"production:mfprj-y22g5oex2j23upte-0-sezo\")\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mIf you want to authorize other people to deploy new versions of this flow to Argo Workflows, they need to call\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    argo-workflows create --authorize mfprj-y22g5oex2j23upte-0-sezo\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mwhen deploying this flow to Argo Workflows for the first time.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mSee \"Organizing Results\" at https://docs.metaflow.org/ for more information about production tokens.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mBootstrapping conda environment...(this could take a few minutes)\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[1mWorkflow \u001b[0m\u001b[31m\u001b[1mfootaxifare.prod.challenger.taxifarepredictionfoo\u001b[0m\u001b[1m for flow \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction_Foo\u001b[0m\u001b[1m pushed to Argo Workflows successfully.\n",
      "\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22mNote that the flow was deployed with a modified name due to Kubernetes naming conventions\n",
      "on Argo Workflows. The original flow name is stored in the workflow annotation.\n",
      "\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[1mSee the deployed workflow here:\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22m    https://argo-pw-1679610794.outerbounds.dev/workflow-templates/jobs-pw-1679610794/footaxifare.prod.challenger.taxifarepredictionfoo\n",
      "    \u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[1mWhat will trigger execution of the workflow:\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22m    This workflow triggers automatically when the upstream \u001b[0m\u001b[31m\u001b[1ms3\u001b[0m\u001b[22m event is/are published.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python ../flows/cloud/foo_taxi_fare_champion_1.py --environment=conda --production --branch challenger argo-workflows create"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Analyze the results\n",
    "Return to this notebook, and read in the results of the challenger and champion flow using the Metaflow Client API.\n",
    "<br><br>\n",
    "\n",
    "#### Questions\n",
    "- Does your model perform better on the metrics you selected? \n",
    "- Think about your day job, how would you go about assessing whether to roll forward the production \"champion\" to your new model? \n",
    "    - What gives you confidence one model is better than another?\n",
    "    - What kinds of information do you need to monitor to get buy-in from stakeholders that model A is preferable to model B?  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONGRATULATIONS! üéâ‚ú®üçæ\n",
    "If you made it this far, you have completed the Full Stack Machine Learning Corise course. \n",
    "We are so glad that you chose to learn with us, and hope to see you again in future courses. Stay tuned for more content and come join us in [Slack](http://slack.outerbounds.co/) to keep learning about Metaflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MetaflowNotFound",
     "evalue": "Flow('TaxiFarePrediction_Foo') does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMetaflowNotFound\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m [CHAMPION_MODEL_NAMESPACE, CHALLENGER_MODEL_NAMESPACE]:\n\u001b[1;32m     10\u001b[0m     namespace(n)\n\u001b[0;32m---> 11\u001b[0m     run \u001b[39m=\u001b[39m Flow(\u001b[39m'\u001b[39;49m\u001b[39mTaxiFarePrediction_Foo\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mlatest_successful_run\n\u001b[1;32m     12\u001b[0m     acc_score \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(run\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mscores)\n\u001b[1;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m acc_score \u001b[39m>\u001b[39m best_score:\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.8/site-packages/metaflow/client/core.py:1900\u001b[0m, in \u001b[0;36mFlow.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1899\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 1900\u001b[0m     \u001b[39msuper\u001b[39;49m(Flow, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.8/site-packages/metaflow/client/core.py:295\u001b[0m, in \u001b[0;36mMetaflowObject.__init__\u001b[0;34m(self, pathspec, attempt, _object, _parent, _namespace_check)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid \u001b[39m=\u001b[39m ids[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    294\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pathspec \u001b[39m=\u001b[39m pathspec\n\u001b[0;32m--> 295\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_object(\u001b[39m*\u001b[39;49mids)\n\u001b[1;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object \u001b[39m=\u001b[39m _object\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.8/site-packages/metaflow/client/core.py:327\u001b[0m, in \u001b[0;36mMetaflowObject._get_object\u001b[0;34m(self, *path_components)\u001b[0m\n\u001b[1;32m    323\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metaflow\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mget_object(\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_NAME, \u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_attempt, \u001b[39m*\u001b[39mpath_components\n\u001b[1;32m    325\u001b[0m )\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result:\n\u001b[0;32m--> 327\u001b[0m     \u001b[39mraise\u001b[39;00m MetaflowNotFound(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m)\n\u001b[1;32m    328\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mMetaflowNotFound\u001b[0m: Flow('TaxiFarePrediction_Foo') does not exist"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from metaflow import Flow, namespace\n",
    "\n",
    "# these values are unique to your deployment!\n",
    "CHAMPION_MODEL_NAMESPACE = \"production:mfprj-sh5wdhgelehxd3cq-0-hrge\"\n",
    "CHALLENGER_MODEL_NAMESPACE = \"production:mfprj-y22g5oex2j23upte-0-sezo\"\n",
    "\n",
    "best_score = -1; winner = None; winner_namespace = None\n",
    "for n in [CHAMPION_MODEL_NAMESPACE, CHALLENGER_MODEL_NAMESPACE]:\n",
    "    namespace(n)\n",
    "    run = Flow('TaxiFarePrediction_Foo').latest_successful_run\n",
    "    acc_score = np.mean(run.data.scores)\n",
    "    if acc_score > best_score:\n",
    "        best_score = acc_score\n",
    "        winner = run.data.model_type\n",
    "        winner_namespace = n\n",
    "print(\"The winner is the {} model, with accuracy of {}%. You can find the model in the flow deployed to the {} namespace.\".format(winner, round(100*best_score, 2), winner_namespace))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full-stack-metaflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
